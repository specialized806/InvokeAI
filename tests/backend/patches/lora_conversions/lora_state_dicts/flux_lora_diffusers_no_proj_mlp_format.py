# A sample state dict in the Diffusers FLUX LoRA format without .proj_mlp layers.
# This format was added in response to https://github.com/invoke-ai/InvokeAI/issues/7129
state_dict_keys = {
    "transformer.single_transformer_blocks.0.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.0.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.0.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.0.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.0.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.0.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.1.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.1.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.1.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.1.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.1.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.1.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.10.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.10.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.10.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.10.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.10.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.10.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.11.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.11.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.11.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.11.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.11.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.11.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.12.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.12.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.12.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.12.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.12.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.12.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.13.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.13.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.13.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.13.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.13.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.13.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.14.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.14.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.14.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.14.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.14.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.14.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.15.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.15.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.15.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.15.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.15.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.15.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.16.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.16.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.16.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.16.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.16.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.16.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.17.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.17.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.17.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.17.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.17.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.17.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.18.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.18.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.18.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.18.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.18.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.18.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.19.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.19.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.19.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.19.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.19.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.19.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.2.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.2.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.2.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.2.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.2.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.2.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.20.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.20.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.20.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.20.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.20.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.20.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.21.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.21.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.21.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.21.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.21.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.21.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.22.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.22.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.22.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.22.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.22.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.22.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.23.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.23.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.23.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.23.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.23.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.23.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.24.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.24.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.24.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.24.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.24.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.24.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.25.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.25.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.25.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.25.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.25.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.25.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.26.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.26.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.26.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.26.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.26.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.26.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.27.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.27.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.27.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.27.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.27.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.27.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.28.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.28.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.28.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.28.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.28.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.28.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.29.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.29.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.29.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.29.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.29.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.29.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.3.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.3.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.3.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.3.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.3.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.3.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.30.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.30.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.30.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.30.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.30.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.30.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.31.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.31.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.31.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.31.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.31.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.31.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.32.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.32.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.32.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.32.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.32.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.32.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.33.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.33.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.33.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.33.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.33.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.33.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.34.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.34.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.34.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.34.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.34.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.34.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.35.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.35.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.35.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.35.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.35.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.35.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.36.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.36.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.36.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.36.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.36.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.36.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.37.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.37.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.37.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.37.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.37.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.37.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.4.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.4.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.4.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.4.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.4.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.4.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.5.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.5.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.5.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.5.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.5.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.5.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.6.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.6.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.6.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.6.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.6.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.6.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.7.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.7.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.7.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.7.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.7.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.7.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.8.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.8.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.8.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.8.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.8.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.8.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.9.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.9.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.9.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.9.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.single_transformer_blocks.9.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.single_transformer_blocks.9.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.0.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.0.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.0.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.0.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.0.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.0.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.0.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.0.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.0.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.0.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.0.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.0.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.0.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.0.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.0.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.0.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.0.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.0.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.0.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.0.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.0.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.0.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.0.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.0.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.1.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.1.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.1.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.1.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.1.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.1.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.1.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.1.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.1.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.1.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.1.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.1.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.1.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.1.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.1.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.1.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.1.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.1.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.1.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.1.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.1.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.1.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.1.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.1.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.10.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.10.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.10.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.10.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.10.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.10.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.10.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.10.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.10.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.10.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.10.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.10.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.10.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.10.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.10.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.10.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.10.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.10.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.10.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.10.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.10.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.10.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.10.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.10.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.11.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.11.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.11.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.11.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.11.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.11.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.11.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.11.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.11.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.11.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.11.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.11.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.11.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.11.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.11.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.11.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.11.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.11.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.11.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.11.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.11.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.11.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.11.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.11.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.12.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.12.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.12.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.12.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.12.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.12.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.12.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.12.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.12.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.12.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.12.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.12.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.12.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.12.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.12.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.12.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.12.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.12.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.12.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.12.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.12.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.12.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.12.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.12.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.13.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.13.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.13.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.13.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.13.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.13.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.13.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.13.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.13.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.13.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.13.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.13.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.13.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.13.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.13.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.13.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.13.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.13.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.13.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.13.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.13.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.13.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.13.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.13.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.14.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.14.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.14.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.14.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.14.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.14.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.14.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.14.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.14.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.14.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.14.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.14.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.14.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.14.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.14.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.14.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.14.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.14.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.14.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.14.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.14.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.14.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.14.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.14.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.15.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.15.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.15.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.15.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.15.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.15.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.15.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.15.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.15.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.15.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.15.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.15.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.15.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.15.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.15.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.15.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.15.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.15.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.15.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.15.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.15.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.15.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.15.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.15.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.16.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.16.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.16.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.16.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.16.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.16.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.16.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.16.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.16.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.16.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.16.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.16.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.16.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.16.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.16.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.16.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.16.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.16.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.16.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.16.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.16.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.16.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.16.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.16.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.17.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.17.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.17.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.17.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.17.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.17.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.17.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.17.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.17.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.17.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.17.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.17.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.17.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.17.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.17.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.17.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.17.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.17.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.17.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.17.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.17.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.17.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.17.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.17.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.18.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.18.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.18.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.18.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.18.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.18.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.18.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.18.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.18.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.18.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.18.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.18.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.18.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.18.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.18.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.18.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.18.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.18.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.18.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.18.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.18.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.18.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.18.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.18.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.2.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.2.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.2.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.2.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.2.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.2.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.2.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.2.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.2.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.2.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.2.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.2.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.2.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.2.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.2.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.2.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.2.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.2.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.2.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.2.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.2.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.2.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.2.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.2.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.3.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.3.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.3.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.3.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.3.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.3.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.3.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.3.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.3.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.3.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.3.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.3.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.3.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.3.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.3.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.3.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.3.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.3.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.3.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.3.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.3.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.3.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.3.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.3.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.4.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.4.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.4.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.4.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.4.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.4.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.4.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.4.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.4.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.4.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.4.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.4.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.4.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.4.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.4.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.4.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.4.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.4.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.4.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.4.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.4.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.4.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.4.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.4.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.5.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.5.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.5.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.5.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.5.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.5.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.5.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.5.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.5.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.5.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.5.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.5.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.5.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.5.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.5.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.5.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.5.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.5.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.5.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.5.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.5.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.5.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.5.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.5.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.6.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.6.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.6.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.6.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.6.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.6.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.6.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.6.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.6.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.6.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.6.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.6.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.6.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.6.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.6.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.6.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.6.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.6.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.6.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.6.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.6.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.6.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.6.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.6.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.7.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.7.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.7.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.7.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.7.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.7.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.7.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.7.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.7.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.7.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.7.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.7.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.7.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.7.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.7.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.7.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.7.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.7.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.7.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.7.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.7.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.7.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.7.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.7.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.8.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.8.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.8.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.8.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.8.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.8.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.8.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.8.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.8.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.8.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.8.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.8.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.8.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.8.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.8.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.8.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.8.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.8.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.8.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.8.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.8.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.8.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.8.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.8.ff_context.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.9.attn.add_k_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.9.attn.add_k_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.9.attn.add_q_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.9.attn.add_q_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.9.attn.add_v_proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.9.attn.add_v_proj.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.9.attn.to_add_out.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.9.attn.to_add_out.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.9.attn.to_k.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.9.attn.to_k.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.9.attn.to_out.0.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.9.attn.to_out.0.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.9.attn.to_q.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.9.attn.to_q.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.9.attn.to_v.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.9.attn.to_v.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.9.ff.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.9.ff.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.9.ff.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.9.ff.net.2.lora_B.weight": [3072, 16],
    "transformer.transformer_blocks.9.ff_context.net.0.proj.lora_A.weight": [16, 3072],
    "transformer.transformer_blocks.9.ff_context.net.0.proj.lora_B.weight": [12288, 16],
    "transformer.transformer_blocks.9.ff_context.net.2.lora_A.weight": [16, 12288],
    "transformer.transformer_blocks.9.ff_context.net.2.lora_B.weight": [3072, 16],
}
